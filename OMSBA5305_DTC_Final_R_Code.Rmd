---
title: "OMSBA5305 Data Translation Challenge, R Code"
output: html_notebook
---

# Load Libraries
```{r}
library(readxl)
library(dynlm) # use the dynlm package
library(urca) #use urca package, allows choosing drift and/or trend for ADF test
library(ggplot2)
library(stats)
library(lmtest) # For Z Statistic
library(forecast) 

```

#Import data and declare time series
```{r}
data<- read_excel("ch3_UnemploymentRate.xls")

#creating time series
unrate <- ts(data$UNRATE, frequency = 12, start = 1948)
data_length <- length(unrate)
unrate_forecast <- ts(data$UNRATE, frequency = 12, start=c(1948,1), end = c(2023,2))

```
## Initial Data Plot 
```{r}
#plotting the data
plot(data, type = 'l', main = 'Unemployment Rate')
ggplot() + 
  geom_line(data, mapping=aes(x=observation_date, y=UNRATE))
```

# Step 1
## Remove Trend and Seasonality
```{r}

#removing trend and seasonality
unrate_d12 <- diff(unrate, differences = 12)
plot(unrate_d12)

unrate_d12 <- diff(unrate, differences = 12)
plot(unrate_d12)
```

## Create ACF & PACF
```{r}
acf(unrate_d12)
pacf(unrate_d12)

acf(unrate)
pacf(unrate)
```

## Create Linear Models
### Linear MA Model
```{r}
MA <- arima(unrate, order = c(0, 0, 1))
ma_r_squared <- as.numeric(MA[2]$sigma2[1])
ma_summary <- summary(MA)
# Calculate the adjusted R-squared value
ma_adjusted_r_squared <- 1 - (1 - ma_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(ma_adjusted_r_squared)

# Z Test
ma_t_stat <- coeftest(MA)
# Print the t-statistics
print(ma_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis.

```

### Linear AR Models
#### AR(1)
```{r}
AR1 <- arima(unrate, order = c(1, 0, 0))
ar1_r_squared <- as.numeric(AR1[2]$sigma2[1])
ar1_summary <- summary(AR1)
# Calculate the adjusted R-squared value
ar1_adjusted_r_squared <- 1 - (1 - ar1_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(ar1_adjusted_r_squared)

# Z Test
ar1_t_stat <- coeftest(AR1)
# Print the t-statistics
print(ar1_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis.

```


#### AR(2)
```{r}
AR2 <- arima(unrate, order = c(2, 0, 0))
ar2_r_squared <- as.numeric(AR2[2]$sigma2[1])
ar2_summary <- summary(AR2)
# Calculate the adjusted R-squared value
ar2_adjusted_r_squared <- 1 - (1 - ar2_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(ar2_adjusted_r_squared)

# Z Test
ar2_t_stat <- coeftest(AR2)
# Print the t-statistics
print(ar2_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis.
```
#### AR(3)
```{r}
AR3 <- arima(unrate, order = c(3, 0, 0))
ar3_r_squared <- as.numeric(AR3[2]$sigma2[1])
ar3_summary <- summary(AR3)
# Calculate the adjusted R-squared value
ar3_adjusted_r_squared <- 1 - (1 - ar3_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(ar3_adjusted_r_squared)

# Z Test
ar3_t_stat <- coeftest(AR3)
# Print the t-statistics
print(ar3_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis.
```


### Linear ARMA Model 1
```{r}
ARMA1 <- arima(unrate, order = c(1, 0, 1))
arma1_r_squared <- as.numeric(ARMA1[2]$sigma2[1])
arma1_summary <- summary(ARMA1)

# Calculate the adjusted R-squared value
arma1_adjusted_r_squared <- 1 - (1 - arma_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(arma1_adjusted_r_squared)

# Z Test
arma1_t_stat <- coeftest(ARMA1)
# Print the t-statistics
print(arma1_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis. In support of AR model. 
```
### Linear ARMA Model 2
```{r}
ARMA2 <- arima(unrate, order = c(2, 0, 1))
arma2_r_squared <- as.numeric(ARMA2[2]$sigma2[1])
arma2_summary <- summary(ARMA2)

# Calculate the adjusted R-squared value
arma2_adjusted_r_squared <- 1 - (1 - arma2_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(arma2_adjusted_r_squared)

# Z Test
arma2_t_stat <- coeftest(ARMA2)
# Print the t-statistics
print(arma2_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis. In support of AR model. 
```

### Linear ARMA Model 3
```{r}
ARMA3 <- arima(unrate, order = c(1, 0, 4))
arma3_r_squared <- as.numeric(ARMA3[2]$sigma2[1])
arma3_summary <- summary(ARMA3)

# Calculate the adjusted R-squared value
arma3_adjusted_r_squared <- 1 - (1 - arma3_r_squared) * (data_length - 1) / (data_length)
# Print the adjusted R-squared value
print(arma3_adjusted_r_squared)

# Z Test
arma3_t_stat <- coeftest(ARMA3)
# Print the t-statistics
print(arma3_t_stat) ### High Z statistics means there is a strong correlation, P value is small so we can reject null hypothesis. In support of AR model. 
```

## Check for stationary 
Test statistic: The Dickey-Fuller test produces a test statistic that measures the strength of evidence against the null hypothesis of non-stationarity. It is denoted as "t-value" or "adf" in the test results. The more negative (or less positive) the test statistic, the stronger the evidence for rejecting the null hypothesis.
```{r}
# Linear MA Model
adf_MA <- ur.df(MA$residuals)
print(adf_MA)
# Linear AR Model
adf_AR <- ur.df(AR$residuals)
print(adf_AR)
# Linear ARMA Model
adf_ARMA <- ur.df(ARMA$residuals)
print(adf_ARMA)
```

##  AIC
AIC stands for Akaike Information Criterion. It is a measure used in statistics to assess the relative quality of statistical models. The AIC value is calculated based on the likelihood function of the model and the number of parameters estimated in the model.

The AIC provides a balance between model fit and model complexity. It penalizes models that have a large number of parameters, favoring simpler models that explain the data well. The goal is to find a model that minimizes the AIC value.

The AIC value is calculated using the following formula:

AIC = -2 * log-likelihood + 2 * k

where:

log-likelihood is the logarithm of the maximum likelihood estimate of the model.
k is the number of parameters estimated in the model.
In general, lower AIC values indicate better-fitting models, as they strike a balance between goodness of fit and model complexity. When comparing multiple models, the model with the lowest AIC value is typically considered the best-fitting model.

It's worth noting that the AIC is a relative measure, meaning that it is useful for comparing different models but does not provide an absolute assessment of model fit or prediction accuracy. Other information criteria, such as the Bayesian Information Criterion (BIC), can also be used for model selection in a similar manner.
```{r}
AIC(MA)
AIC(AR1)
AIC(AR2)
AIC(AR3)


AIC(ARMA1)
AIC(ARMA2)
AIC(ARMA3)
```

## BIC 
BIC stands for Bayesian Information Criterion. It is another criterion used for model selection in statistics. Like the AIC (Akaike Information Criterion), the BIC provides a measure of the relative quality of statistical models.

The BIC takes into account both the goodness of fit of the model and the complexity of the model, similar to the AIC. However, the BIC places a higher penalty on model complexity than the AIC. It is derived from a Bayesian perspective, assuming a uniform prior distribution over the model parameters.

The BIC value is calculated using the following formula:

BIC = -2 * log-likelihood + log(n) * k

where:

log-likelihood is the logarithm of the maximum likelihood estimate of the model.
n is the number of observations in the data.
k is the number of parameters estimated in the model.
The BIC penalizes models with more parameters more heavily than the AIC, effectively favoring simpler models. Therefore, the BIC tends to produce a more parsimonious model compared to the AIC.

Similar to the AIC, lower BIC values indicate better-fitting models. When comparing multiple models, the model with the lowest BIC value is typically considered the best-fitting model.

It's important to note that the AIC and BIC are both useful criteria for model selection, and the choice between them depends on the specific context and preferences. In some cases, the AIC may favor more complex models, while the BIC tends to favor simpler models.
```{r}
BIC(MA)
BIC(AR1)
BIC(AR2)
BIC(AR3)

BIC(ARMA1)
BIC(ARMA2)
BIC(ARMA3)
```


## Ljung Box Test
The test is based on the Ljung-Box statistic, which measures the overall autocorrelation of the residuals at different lags. The null hypothesis of the test is that there is no autocorrelation in the residuals.
```{r}
Box.test(unrate, type='Ljung-Box')
```











#Step 2:
##Import data and declare time series
Declaration: An Excel file named "ch3_UnemploymentRate.xls" is read using read_excel(). The data is then divided into the first 90% portion (data_first_90pct) and the estimation sample (data_estimation_sample). A time series object unrate_forecast is created based on the "UNRATE" column.
```{r}
# create train data, first 90%
data_row_ct <- nrow(data)
data_first_90pct <- data[1:ceiling(0.9*data_row_ct),]
data_first_90pct_row_ct <- nrow(data_first_90pct)
# set test data
data_estimation_sample <- tail(data, data_row_ct-ceiling(0.9*data_row_ct))
data_estimation_sample_row_ct <- data_row_ct-ceiling(0.9*data_row_ct)

```

## Model 1: AR(3) (Fixed Scheme): 
An AR(3) model is fitted to the estimation sample using dynlm(). The model is summarized, and a for loop is used to generate forecasts (fcast1) and forecast errors (ferror1) based on the model coefficients. The mean squared error (MSE) is calculated (MSE1). The model is then tested for forecast optimality using the MPE test and the informational efficiency test.

### 90% Control, 10% Test
```{r}
#fit AR(3)
ar3_model<-dynlm(unrate_forecast ~ lag(unrate_forecast,-1) + lag(unrate_forecast,-3), start=c(1948,1), end=c(2023,2)) 
summary(ar3_model)


fcast1<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
ferror1<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
loss1<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)

for (i in 1:data_estimation_sample_row_ct){ #start a for loop 
  #fill in forecasted values at the end of each iteration
  ## Forecast values
  fcast1[i]<-coef(ar3_model)[1]+ coef(ar3_model)[2]*unrate_forecast[data_first_90pct_row_ct-1+i] + coef(ar3_model)[3]*unrate_forecast[data_first_90pct_row_ct-3+i]
  ## Error Values
  ferror1[i]<-unrate_forecast[data_first_90pct_row_ct+i]- fcast1[i]
  ## Loss Values
  loss1[i] <-ferror1[i]^2
} #end the loop

# cbind(fcast1, ferror1, loss1)
MSE1 <- mean(loss1)

mpetest <- lm(ferror1 ~ 1)
summary(mpetest)

IETest <- lm(ferror1 ~ fcast1)
summary(IETest)

```

### AR(3) One Step Ahead
```{r}
ar3_onestep <- rbind(NA,NA,NA, data.frame(predict(ar3_model, h=1)))
colnames(ar3_onestep)[1] <- "forecast"
error_onestep <- test$UNRATE - test$forecast
loss_onestep <- (test$UNRATE - test$forecast)^2
fAR3_onestep <- cbind(data, ar3_onestep$forecast, error_onestep, loss_onestep)
```


## Model 2: Naive Forecast: 
A naive forecast is generated by assigning the previous observation as the forecast value (fcast2). Forecast errors and MSE are calculated, and the model is tested for forecast optimality.
```{r}
fcast2<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
ferror2<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
loss2<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)

for (i in 1:data_estimation_sample_row_ct){ 
  fcast2[i]<-unrate_forecast[data_first_90pct_row_ct-1+i] #naive forecast
  ferror2[i]<-unrate_forecast[data_first_90pct_row_ct+i]- fcast2[i] #fill in forecasted values at the end of each iteration
  loss2[i] <-ferror2[i]^2
 } 
cbind(fcast2, ferror2, loss2)
MSE2 <- mean(loss2)

mpetest <- lm(ferror2 ~ 1)
summary(mpetest)


IETest <- lm(ferror2 ~ fcast2)
summary(IETest)

```


#Model 3: Average-4 Forecast: 
The forecast is calculated as the average of the last four observations (fcast3). Forecast errors and MSE are calculated, and the model is tested for forecast optimality.
```{r}
fcast3<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
ferror3<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
loss3<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)


for (i in 1:data_estimation_sample_row_ct){ 
  fcast3[i]<-(unrate_forecast[data_estimation_sample_row_ct-1+i]+unrate_forecast[data_estimation_sample_row_ct-2+i]+unrate_forecast[data_estimation_sample_row_ct-3+i]+unrate_forecast[data_estimation_sample_row_ct-4+i])/4  #forecast is the average of the last 4 observations
  ferror3[i]<-unrate_forecast[data_first_90pct_row_ct+i] - fcast3[i] #fill in forecasted values at the end of each iteration
  loss3[i] <-ferror3[i]^2
}


cbind(fcast3, ferror3, loss3)
MSE3 <- mean(loss3)

mpetest <- lm(ferror3 ~ 1)
summary(mpetest)


IETest <- lm(ferror3 ~ fcast3)
summary(IETest)

```

## Optimal Linear Combinations: 
An optimal linear combination of the three forecasts is created using the lm() function (comb). The fitted values of the combination model are used as the forecast values (fcast4). Forecast errors and MSE are calculated for this combined forecast (ferror4, loss4, and MSE4).
```{r}

unrate_forecast0<-window(unrate_forecast,start=c(2015,9)) ## estimation sample date
comb<-lm(unrate_forecast0~fcast1+fcast2+fcast3)
summary(comb)


fcast4<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
ferror4<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)
loss4<-numeric(data_estimation_sample_row_ct) #generate a vector of zeros (length of estimation sample set)

fcast4 <- comb$fitted.values
ferror4 <- unrate_forecast0-fcast4
loss4 <-ferror4^2

MSE4 <- mean(loss4)
```

# Forecasts Findings Overview
```{r}
data_estimation_sample
cbind(data_estimation_sample, fcast1, ferror1, loss1, fcast2, ferror2, loss2, fcast3, ferror3, loss3)
```

# Plots
```{r}
forec <- cbind(data_estimation_sample,fcast1, fcast2, fcast3, fcast4)
## Adjust date tye
forec$observation_date = as.Date(forec$observation_date)
data$observation_date = as.Date(data$observation_date)
forec
```
## Full Timeseries Plot + Forecast
```{r}
plot(x = data$observation_date, y = data$UNRATE, type = "l", lwd=3.0)+
  lines(x = forec$observation_date, y= forec$fcast1,lty=2,lwd=2,col="green")+
  lines(x = forec$observation_date, y= forec$fcast2,lty=2,lwd=2,col="red")+
  lines(x = forec$observation_date, y= forec$fcast3,lty=2,lwd=2,col="orange")
# +
#   lines(x = forec$observation_date, y= forec$fcast4,lty=2,lwd=2,col="purple")

```

## Estimation Sample Plot
```{r}

plot(x = data$observation_date, y = data$UNRATE, type = "l", lwd=5.0, xlim=c(as.Date("2015-01-01"), as.Date("2023-01-04")) )+
  lines(x = forec$observation_date, y= forec$fcast1,lty=2,lwd=2,col="green")+
  lines(x = forec$observation_date, y= forec$fcast2,lty=2,lwd=2,col="red")+
  lines(x = forec$observation_date, y= forec$fcast3,lty=2,lwd=2,col="orange")
# +
#   lines(x = forec$observation_date, y= forec$fcast4,lty=2,lwd=2,col="purple")

```



```{r}
plot(x = data$observation_date, y = data$UNRATE, type = "l", lwd=5.0, xlim=c(as.Date("2020-01-01"), as.Date("2023-01-04")) )+
  lines(x = forec$observation_date, y= forec$fcast1,lty=2,lwd=2,col="green")+
  lines(x = forec$observation_date, y= forec$fcast2,lty=2,lwd=2,col="red")+
  lines(x = forec$observation_date, y= forec$fcast3,lty=2,lwd=2,col="orange")
# +
#   lines(x = forec$observation_date, y= forec$fcast4,lty=2,lwd=2,col="purple")

```

```{r}
plot(x = data$observation_date, y = data$UNRATE, type = "l", lwd=5.0, xlim=c(as.Date("2021-01-01"), as.Date("2023-01-04")) )+
  lines(x = forec$observation_date, y= forec$fcast1,lty=2,lwd=2,col="green")+
  lines(x = forec$observation_date, y= forec$fcast2,lty=2,lwd=2,col="red")+
  lines(x = forec$observation_date, y= forec$fcast3,lty=2,lwd=2,col="orange")

```

## Forcasted Data Plot
```{r}
ggplot() + 
  geom_line(data, mapping=aes(x=observation_date, y=UNRATE),size=1) +
  geom_line(forec, mapping=aes(x=observation_date, y=fcast1, color= 'Model 1: Fixed Scheme'),size=1) +
  geom_line(forec, mapping=aes(x=observation_date, y=fcast2, color='Model 2: Naive'),size=1) +
  geom_line(forec, mapping=aes(x=observation_date, y=fcast3, color='Model 3: Average-4'),size=1) +
  #geom_line(forec, mapping=aes(x=observation_date, y=fcast4, color='fcast4'),size=1) +
  xlim(as.Date(c("2015-01-01", "2023-01-01"))) +
  labs(title="GDP Forecast", colour="Forecasts") +
  xlab("Date") +
  ylab("GDP MoM% Rate")
```

## Forcasted Data Plot
```{r}
ggplot() + 
  geom_line(data, mapping=aes(x=observation_date, y=UNRATE),size=1) +
  geom_line(forec, mapping=aes(x=observation_date, y=fcast1, color= 'Model 1: Fixed Scheme'),size=1) +
  geom_line(forec, mapping=aes(x=observation_date, y=fcast2, color='Model 2: Naive'),size=1) +
  geom_line(forec, mapping=aes(x=observation_date, y=fcast3, color='Model 3: Average-4'),size=1) +
  #geom_line(forec, mapping=aes(x=observation_date, y=fcast4, color='fcast4'),size=1) +
  xlim(as.Date(c("1948-01-01", "2023-01-01"))) +
  labs(title="GDP Forecast", colour="Forecasts") +
  xlab("Date") +
  ylab("GDP MoM% Rate")+
  theme(aspect.ratio=1/2)
```



# Part 3
## Part 1 Simulation ###
```{r}
#P258 Generate time trend
t=c(1:50) #generate t=1,2,...50
y=1+.5*t+rnorm(50) #y=1+.5*trend + normal white noise
ts.plot(y) #plot y
lines(.5*t) #also plot the trend


#P271 Generate randm walk
y=numeric(500) #generate a vector of 500 zeros
for (i in 2:500){ #start a for loop
  y[i]=y[i-1]+rnorm(1) #generate random walk without drift
} #end the loop
ts.plot(y) #plot y
lines(numeric(500)) #also plot horizontal line at zero

ts.plot(cumsum(rnorm(500))) #another way to generate random walk without drift


y=numeric(500) #generate a vector of 500 zeros
for (i in 2:500){ 
  y[i]=.5+y[i-1]+rnorm(1) #generate random walk with drift
}
ts.plot(y) #plot y
lines(.5*c(1:500)) #also plot trend .5*t


# P277 model for case I, showin in fig10.8a (You should run this serveral times to see the variation)
y=numeric(500) #generate a vector of 500 zeros
for (i in 2:500){ 
  y[i]=0.9988*y[i-1]+rnorm(1) #generate random walk without drift
}
ts.plot(y) #plot y
lines(0*c(1:500)) #also plot trend .5*t

# P277 model for case II 
y=numeric(500) #generate a vector of 500 zeros
for (i in 2:500){ 
  y[i]=-0.325+0.9905*y[i-1]+rnorm(1) #generate random walk with drift
}
ts.plot(y) #plot y
lines(0*c(1:500)) #also plot trend .5*t

# P277 model for case III showin in fig10.8b
y=numeric(500) #generate a vector of 500 zeros
for (i in 2:500){ 
  y[i]=0.9167+0.0082i+0.9830*y[i-1]+rnorm(1) #generate random walk with drift and a time trend
}
ts.plot(y) #plot y
lines(0*c(1:500)) #also plot trend .5*t

## Part 2 Deterministic trend  ###
#P266
library(readxl)
data <- read_excel("Figure10_5_MortgageDebt.xls")
debt<-ts(data$`MORTGAGE DEBT`, frequency =4, start = c(1992,1)) #declare debt as quarterly time series
plot(debt)

trend1 = ts(c(1:49), frequency = 4, start = c(1992,1)) #trend1=1,2,3...60, declared to be time-series
model <-lm(debt ~ poly(trend1, 4, raw=TRUE)) # y=b0+b1*t+b2*t^2+b3*t^31+b4*t^4+WN
summary(model) #estimation output

AIC(model) #AIC
## [1] 434.5619
BIC(model) #BIS
## [1] 445.9129

plot.ts(debt, ylab="", lty=2) #plot debt w/o y-axis title, dashed
fit = ts(fitted(model), frequency = 4, start=c(1992,1)) #declare fit as quarterly time series
res = ts(resid(model), frequency = 4, start=c(1992,1)) #declare res as quarterly time series
lines(fit, col="red", lty=2) #also plot fit in red color
par(new=TRUE) #following series will be graphed on the existing plot
plot.ts(res, axes=FALSE, ylab="", col="blue") #plot residuals w/o y-axis title, in blue color
axis(side=4, at = pretty(range(res))) #add the right y-axis for residuals
legend("topleft", legend=c("Actual", "Fit", "Res"), lty=c(2,2,1), col=c("black", "red", "blue")) #legend, debt and fit will be dashed 

acf(res) #ACF of residuals of the 4th order polynomial trend model
pacf(res) #PACF of residuals of the 4th order polynomial trend model

#P268
#install.packages("dynlm") #install dynamic linear modelling package
library(dynlm) #dynlm is required for using lag operators
model <- dynlm(debt ~ trend1+I(trend1^2)+I(trend1^3)+I(trend1^4)+lag(debt,-1)+lag(debt,-2)) #AR(2) + polynomial(4) trend
summary(model) #estimation output

AIC(model) #AIC
## [1] 394.7132
BIC(model) #BIS
## [1] 409.5144

#P269

plot.ts(debt, ylab="", lty=2) #plot debt w/o y-axis title, dashed
fit = ts(fitted(model), frequency = 4, start=c(1992,3)) #declare fit as quarterly time series, note that fitted values start drom 1992q3 because it is an AR(2) model
res = ts(resid(model), frequency = 4, start=c(1992,1)) #declare res as quarterly time series
lines(fit, col="red", lty=2) #also plot fit in red color
par(new=TRUE) #following series will be graphed on the existing plot
plot.ts(res, axes=FALSE, ylab="", col="blue") #plot residuals w/o y-axis title, in blue color
axis(side=4, at = pretty(range(res))) #add the right y-axis for residuals
legend("topleft", legend=c("Actual", "Fit", "Res"), lty=c(2,2,1), col=c("black", "red", "blue")) #legend, debt and fit will be dashed 


## Part 3 Dickey-Fuller Test   ###
#P286
dickey_fuller_test <- ur.df(unrate,type="drift",lags=1) 
summary(dickey_fuller_test)


ur.df(unrate,type="drift",lags=0) 
ur.df(diff(unrate),type="drift",lags=0) 
ur.df(diff(diff(unrate)),type="drift",lags=0) 

dunrate<-diff(unrate)
model_dickey_fuller <-dynlm(dunrate ~ lag(unrate,-1)) #regression correspondong to the above ADF test
summary(model_dickey_fuller) #estimation output
AIC(model_dickey_fuller)
## [1] 171.2994
BIC(model_dickey_fuller)
## [1] 175.6966
res_dickey_fuller<-  residuals(model_dickey_fuller) #generate residuals
acf(res_dickey_fuller)
pacf(res_dickey_fuller)


model_lag1 <-dynlm(dunrate ~ lag(unrate,-1)+lag(dunrate,-1)) #regression corresponding to the above ADF test
summary(model_lag1)

AIC(model_lag1)
## [1] 134.9974
BIC(model_lag1)
## [1] 140.7334
res_lag1<-  residuals(model_lag1)
acf(res_lag1)
pacf(res_lag1)


# P287 Prepare to forecast table 10.8 
model_ar1 <-dynlm(dunrate ~ lag(dunrate,-1)+0) #AR(1) w/o constant for differenced series
summary(model_ar1)
AIC(model_ar1)
## [1] 135.857
BIC(model_ar1)
## [1] 138.725

fcast_ar1=union(unrate, c(1,2,3,4)) #fcast will include actual SPAIN and 4 forecasts for SPAIN
fcastd_ar1=union(dunrate, c(1,2,3,4)) #fcastd will include actual dSPAIN and 4 forecasts for dSPAIN

for(i in 1:4){
  fcastd_ar1[32+i]=coef(model_ar1)[1]*fcastd_ar1[31+i] #manually retrieving forecasts from AR(1) model for dSPAIN
  fcast_ar1[33+i]=fcast_ar1[32+i]+fcast_ar1[32+i] #the forecast for fcast_t = fcast_t-1 +fcastd_t (note that fcastd is one period "behind", thats why the last term is fcastd[32+i], and not fcastd[33+i])
}

# P288, fig 10.13
fcast = ts(fcast, frequency = 1, start = 1970)
ts.plot(fcast) #plot of the forecast
lines(SPAIN, col=6) #simualtaneous plotting of the actual series in magenta color


#P289 do the same for the u.s.
ur.df(USA,type="trend",lags=1) #ADF for USA with trend and constat
model <- dynlm(diff(USA) ~ lag(USA,-1)+diff(lag(USA,-1))+trend(USA)) #corresponding regression
summary(model)
AIC(model)
## [1] 104.6664
BIC(model)
## [1] 111.8363
model <- dynlm(USA ~ lag(USA,-1)+lag(USA,-2)+trend(USA)) #AR(2) with trend and constant
summary(model)
AIC(model)
## [1] 104.6664
BIC(model)
## [1] 111.8363
```


